\subsection{Практические последствия}

\begin{frame}
	\tableofcontents[currentsection,currentsubsection]
\end{frame}

\begin{frame}[fragile]{Хранятся только старшие знаки}
\begin{minted}{python}
for a in [2.0 ** x for x in [10, 20, 40, 60, 1000]]:
    print(a == a + 1, a == a * (1 + 2 ** (-40)), a + 1 - a)
\end{minted}
	В Python у нас тип двойной точности, поэтому до $2^{40}$ единица ещё будет играть роль, а вот после "--- нет.

	Складывать/вычитать числа разных порядков "--- плохо.
	Сильно теряется точность.
	Одного порядка "--- нормально.

\end{frame}

\begin{frame}[fragile]{Ошибка может копиться}
\begin{minted}{python}
from random import shuffle
a=[123456 * 2 ** x for x in range(0, 200)]
print(format(sum(a), ".20e"))  # Точный результат
a = list(map(float, a))
for _ in range(10):
    shuffle(a)
    print(format(sum(a), ".20e"))
\end{minted}
	Так как результаты округляются на каждом шаге, результат может зависеть от порядка вычислений, размеров чисел и фазы луны.

	Пример "--- метод Гаусса (подробнее расскажут на алгоритмах) решения систем.
	Уже для матриц $15 \times 15$ можно подобрать матрицу, на которой точность теряется катастрофически быстро.

	А вот с одним порядком:
\begin{minted}{python}
from random import randrange, shuffle
a=[randrange(1000000000) * 2 ** 100 for _ in range(0, 200)]
print(format(sum(a), ".20e"))  # Точный результат
a = list(map(float, a))
for _ in range(10):
    shuffle(a)
    print(format(sum(a), ".20e"))
\end{minted}
\end{frame}

\begin{frame}{Оптимизатор}
	\includegraphics[scale=0.5]{optimizer-game.jpg}
\end{frame}

\begin{frame}{Оптимизатор}
	Часто процессор поддерживает числа большего размера, чем double-precision.
	Тогда точность может в некоторых местах случайно возрастать, а оптимизатор об этом не догадывается.
	Например, <<побитово равные>> числа могут \href{http://codeforces.com/blog/entry/1059}{оказаться различными} "--- в одном месте сравнили куски памяти,
	а в других местах "--- лежащие в процессоре числа.
\end{frame}

\begin{frame}[fragile]{Десятичные дроби неточны}
\begin{minted}{python}
print(0.1 + 0.2)  # Классика
print(format(0.1 + 0.2, ".100f"))
print(format((0.1 + 0.2) * 2 ** 52, ".100f"))
for n in [1000, 1024]:
    fail, total = 0, 0
    for a in range(n):
        for b in range(n):
            if (a + b) / n != a / n + b / n:
                fail += 1
            total += 1
    print(fail, total, fail / total)
\end{minted}
\end{frame}

\begin{frame}{Что делать?}
	Не использовать вещественные числа как можно больше.
	Особенно на контестах.
	Особенно у Серёжи.

	Если очень надо "--- готовиться к неточности и допускать погрешность при \textit{любых} сравнениях (см. оптимизатор):
	\begin{center}
		\begin{tabular}{|c|c|}
			\hline
			Было & Стало \\\hline
			\t{a == b} & \t{abs(a - b) < eps} \\\hline
			\t{a <= b} & \t{a <= b + eps}  \\\hline
			\t{a < b} & \t{a < b - eps} \\\hline
		\end{tabular}
	\end{center}
	Тут мы считаем, что числа равны, если отличаются не более, чем на \t{eps}.
	Можно ещё более аккуратно, если смотреть на относительную погрешность, а не абсолютную.

	Подбор \t{eps} и правильного порядка операций "--- отдельное искусство, обычно на контестах берут от $10^{-5}$ до $10^{-15}$; мой любимый "--- $10^{-8}$.
	При желании может строго теоретически обосновать.

	Например, вместо $x^2-y^2$ считается, что лучше использовать $(x-y)(x+y)$.
\end{frame}

\begin{frame}[fragile]{Странные вычисления}
	Осторожно с \t{NaN}: любое вычисление с ним немедленно породит \t{NaN}, а сравнения с ним всегда выдают \t{false}:
\begin{minted}{python}
from math import sqrt
print(2 ** 1000 / 2 ** (-1000))
print(-2 ** 1000 / 2 ** (-1000))
print(sqrt(0), sqrt(2 ** (-1000)))
print(0 * float('inf'))
print(1 + float('nan'))
print(float('nan') == float('nan'))
\end{minted}
	В C++ его ещё можно получить, взяв корень из отрицательного числа или $\frac{0}{0}$ (Python может кинуть исключение).

	Когда извлекаете корень, не извлеките его случайно из \t{-eps}, стоит писать \t{sqrt(max(x, 0))}.
\end{frame}
